{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b450db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import transformers\n",
    "import spacy\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98b7c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"dslim/nasdaq_labeled_companies_holdings.csv\",index_col=False,header=0)\n",
    "df_all_extracted_companies = pd.read_csv(\"dslim/all_companies_nasdaq.csv\",index_col=False,header=0)\n",
    "df_news = pd.read_csv(\"dslim/nasdaq_labeled_news.csv\",index_col=False,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17043d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "COMMENT = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c44827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "517664e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_words = [\"america\",\"bank\",\"health\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87362ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_match(real_str, extracted_str):\n",
    "    global COMMENT\n",
    "    words = real_str.title().replace(\"-\",\"\").split(\" \")#for walmart and other\n",
    "    for word in words:\n",
    "        for feature in feature_words:\n",
    "            if (word.lower().find(feature)!=-1) and extracted_str.lower().find(feature)==-1:\n",
    "                return False\n",
    "        if(word not in extracted_str):\n",
    "            return False\n",
    "    COMMENT = \"Vaild words match\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b597230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_also_proper(real_str, extracted_str,nlp):\n",
    "    global COMMENT\n",
    "    doc = nlp(real_str)\n",
    "    for tok in doc: \n",
    "        if(tok.pos_ == 'PROPN' and extracted_str.replace(\"-\",\"\").title().find(tok.text)==-1 and tok.text not in tokenizer.get_vocab() and len(tok.text)>3):\n",
    "            return False\n",
    "        if(tok.pos_ == 'PROPN' and extracted_str.replace(\"-\",\"\").title().find(tok.text)!=-1 and tok.text not in tokenizer.get_vocab() and len(tok.text)>3):\n",
    "            COMMENT = \"Both companies have same proper name\"\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b27317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_also_person(real_str, extracted_str,nlp):\n",
    "    global COMMENT\n",
    "    doc = nlp(real_str)\n",
    "    for ent in doc.ents: \n",
    "        if(ent.label_ == 'PERSON' and extracted_str.find(ent.text)!=-1 and len(ent.label > 2)):\n",
    "            COMMENT = \"Both companies have same person name\"\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd0ace1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_both_unique(real_str, extracted_str):#check if organisation name contains unique word\n",
    "    global COMMENT\n",
    "    words = real_str.replace(\"-\",\"\").split(\" \")\n",
    "    if(len(words)==1 and len(extracted_str.replace(\"-\",\"\").split(\" \"))==1):#one subword - not valid\n",
    "        return False\n",
    "    for word in words:\n",
    "        if(word in extracted_str and word not in tokenizer.get_vocab()):\n",
    "            COMMENT = \"Both companies have unique word\"\n",
    "            return True\n",
    "    words = real_str.split(\" \")\n",
    "    for word in words:\n",
    "        if(word in extracted_str and word not in tokenizer.get_vocab()):\n",
    "            COMMENT = \"Both companies have unique word\"\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "047a270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_extracted_contain_real(real_str, extracted_str):#check if organisation name contains person name\n",
    "    words = real_str.replace(\"-\",\" \").lower().split(\" \")\n",
    "    for word in words:\n",
    "        if(word not in extracted_str.lower()):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d667387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_arconym(real_str, extracted_str):\n",
    "    global COMMENT\n",
    "    company = real_str.lower()\n",
    "    extracted = extracted_str.replace(\"-\",\" \").lower().split(\" \")\n",
    "    extracted = [elem for elem in extracted if len(elem)!=0]\n",
    "    if(len(company)!=len(extracted)): \n",
    "        extracted.append(\"group\")\n",
    "    if(len(company)!=len(extracted)):\n",
    "        return False\n",
    "    for idx in range(len(extracted)):\n",
    "        if(company[idx]!=extracted[idx][0]):\n",
    "            return False\n",
    "    COMMENT = \"Company is acronym\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34cbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching:\n",
    "res_df = pd.DataFrame(columns=['Real company','Extracted company','Metrix','Comment','Article'])\n",
    "\n",
    "found_num = 0\n",
    "not_found_num = 0\n",
    "total = 0\n",
    "\n",
    "labeled_companies = df_labels['Name']\n",
    "news = df_news['News']\n",
    "\n",
    "ARTICLES_NUM = len(labeled_companies)\n",
    "extracted_companies = df_all_extracted_companies['Name']\n",
    "perfect_companies = 0\n",
    "contain_real_companies = 0\n",
    "\n",
    "for idx in range (ARTICLES_NUM):\n",
    "    labeled = labeled_companies[idx].split('\\t')\n",
    "    extracted = extracted_companies[idx].split('\\t')\n",
    "    total += len(labeled)\n",
    "    for labeled_elem in labeled:\n",
    "        max_metrix = 0.0\n",
    "        COMMENT = \"\"\n",
    "        for extracted_elem in extracted:\n",
    "            labeled_str = labeled_elem.replace(\" \",\"\").replace(\"-\",\"\").lower()\n",
    "            extracted_str = extracted_elem.replace(\" \",\"\").replace(\"-\",\"\").lower()\n",
    "            metrix = difflib.SequenceMatcher(None,labeled_str,extracted_str).ratio()\n",
    "                \n",
    "            if (metrix == 1.0):\n",
    "                max_elem = extracted_elem\n",
    "                max_metrix = 1.0\n",
    "                perfect_companies += 1\n",
    "                break\n",
    "            if (is_extracted_contain_real(labeled_elem,extracted_elem)):\n",
    "                max_elem = extracted_elem\n",
    "                max_metrix = 1.0\n",
    "                contain_real_companies += 1\n",
    "                COMMENT = \"Extracted company contain real\"\n",
    "                break\n",
    "            if (metrix > 0.3 and len(extracted_str) > 2 and (len(labeled_str) > 2) and (is_valid_match(labeled_elem,extracted_elem) or is_valid_match(extracted_elem,labeled_elem) or is_also_proper(labeled_elem,extracted_elem,nlp) or is_both_unique(labeled_elem,extracted_elem))):\n",
    "                max_metrix = 0.95\n",
    "                max_elem = extracted_elem\n",
    "            if metrix > max_metrix:\n",
    "                max_metrix = metrix\n",
    "                max_elem = extracted_elem\n",
    "                COMMENT = \"\"\n",
    "            if (is_arconym(labeled_elem,extracted_elem) or is_arconym(extracted_elem,labeled_elem)):\n",
    "                max_metrix = 0.8\n",
    "                max_elem = extracted_elem\n",
    "        if (max_metrix > 0.95)or(max_metrix > 0.8  and len(labeled_elem) > 2 and len(max_elem) > 2):      \n",
    "            res_df.loc[found_num]=[labeled_elem,max_elem,max_metrix,COMMENT,news[idx]]\n",
    "            found_num += 1\n",
    "        else:\n",
    "            not_found_num += 1\n",
    "            #print(labeled_elem,\"+\", extracted,\" best: \",max_elem,\" :idx = \",idx)\n",
    "print(\"not found\", not_found_num)\n",
    "print(\"found\", found_num)\n",
    "print(\"total\",total)\n",
    "print(\"found_res = \",found_num/total)\n",
    "print(\"perfect_res = \",perfect_companies/total)\n",
    "print(\"contained_res = \",contain_real_companies/total)\n",
    "print(res_df.count())\n",
    "res_df.drop_duplicates(subset=['Real company','Extracted company'],inplace=True)\n",
    "print(res_df.count())\n",
    "res_df.to_csv(\"results/extracted_res_with_alice_improved.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
