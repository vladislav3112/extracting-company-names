{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b450db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import transformers\n",
    "import spacy\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c791e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "commonly_used_words = [\"of\",\"america\",\"american\",\"taiwan\",\"banco\",\"mexico\",\"china\",\"health\",\"healthcare\",\"pharma\",\"pharmaceutical\",\"us\",\"partners\",\"united states\",\"managment\",\"mosaic\",\n",
    "                       \"financial\",\"bank\",\"companies\",\"services\",\"products\",\"brands\",\"air\",\"airlines\",\"international\",\"asset\",\"equity\",\"fund\",\"group\",\"resourses\",\"technologies\",\"hotels\",\"control\",\"controls\",\"black\",\"green\",\"natural\",\"steel\",\"motor\",\n",
    "                       \"general\",\"resourses\",\"electric\",\"payments\",\"home\",\"world\",\"union\",\"credit\",\"business\",\"public\",\"shipping\",\"capital\",\"express\",\"royal\",\"mobile\",\"microelectronics\"\n",
    "                       \"first\",\"exchange\",\"block\",\"united\",\"energy\",\"national\",\"realty\",\"york\",\"titan\",\"community\",\"skin\",\"foods\",\"industrial\",\"iron\",\"paper\",\"crown\",\"petroleum\",\"jewelers\",\"communications\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b7c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"news_handled/ls_new_nasdaq_labeled_companies_holdings.csv\",index_col=False,header=0)\n",
    "df_all_extracted_companies = pd.read_csv(\"news_handled/ls_new_all_companies_nasdaq_normalized.csv\",index_col=False,header=0)\n",
    "df_news = pd.read_csv(\"news_handled/nasdaq_news.csv\",index_col=False,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17043d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Name  \\\n",
      "0                                           US Steel   \n",
      "1                 Taiwan Semiconductor Manufacturing   \n",
      "2                            United Microelectronics   \n",
      "3                                Goldman Sachs Group   \n",
      "4  American Tower\\tBlackstone\\tCrown Castle Inter...   \n",
      "\n",
      "                                           Long name  \n",
      "0                           United States Steel Corp  \n",
      "1         Taiwan Semiconductor Manufacturing Company  \n",
      "2                       United Microelectronics Corp  \n",
      "3                            Goldman Sachs Group Inc  \n",
      "4  American Tower Corp\\tBlackstone Inc\\tCrown Cas...  \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "COMMENT = \"\"\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd42ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_geo(real_str):\n",
    "    global COMMENT\n",
    "    doc = nlp(real_str)\n",
    "    for ent in doc.ents: \n",
    "        if(ent.label_ == 'GPE' or ent.label_ == 'GEO'):\n",
    "            print(ent.text)\n",
    "            print(ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c927ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winnebago\n",
      "GPE\n"
     ]
    }
   ],
   "source": [
    "print_geo(\"Since 1958, Winnebago has been innovating recreation–from SmartSpace design to advanced steel chassis-based safety features and everything in between–and \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c44827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a7e4c93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_geo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_665660/1088338351.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_geo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Yum Brands claimed today than Tim and Ben was yesterday in small town called Aruba\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_geo' is not defined"
     ]
    }
   ],
   "source": [
    "print(print_geo(\"Yum Brands claimed today than Tim and Ben was yesterday in small town called Aruba\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "517664e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(commonly_used_words[0])\n",
    "print(\"brands\" in commonly_used_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87362ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_match(real_str, extracted_str):\n",
    "    global COMMENT\n",
    "    \n",
    "    all_real_words_is_common = True\n",
    "    all_extracted_words_is_common = True\n",
    "    real_words = real_str.lower().replace(\"-\",\" \").split(\" \")#for walmart and other\n",
    "    extracted_words = extracted_str.lower().replace(\"-\",\" \").split(\" \")\n",
    "    \n",
    "    \n",
    "    for word in real_words:\n",
    "        if(word not in commonly_used_words and len(word) > 3):\n",
    "            all_real_words_is_common = False\n",
    "            \n",
    "    if(all_real_words_is_common):\n",
    "        COMMENT = \"all words in real is commonly used, only full match avaliable\"\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    for word in extracted_words:\n",
    "        if(word not in commonly_used_words and len(word) > 3):\n",
    "            all_extracted_words_is_common = False\n",
    "    if(all_extracted_words_is_common):\n",
    "        COMMENT = \"all words in extracted company is commonly used, only full match avaliable\"\n",
    "        return False\n",
    "    \n",
    "    if(len(real_words) > 1 and len(extracted_words) > 1 and real_str.replace(\" \",\"\").find(extracted_str)!=-1 ):\n",
    "        COMMENT = \"Vaild words match\"\n",
    "        return True\n",
    "    \n",
    "    for word in extracted_words:\n",
    "        if(word not in real_words):\n",
    "            return False\n",
    "    COMMENT = \"Vaild words match\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b597230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_also_proper(real_str, extracted_str,nlp):\n",
    "    global COMMENT\n",
    "    doc = nlp(real_str)\n",
    "    \n",
    "    for tok in doc: \n",
    "        if(tok.pos_ == 'PROPN' and extracted_str.replace(\"-\",\"\").title().find(tok.text)==-1 and tok.text not in tokenizer.get_vocab() and len(tok.text)>3 and tok.text.lower not in commonly_used_words):\n",
    "            return False\n",
    "        if(not tok.text.isupper() and tok.text.lower() not in commonly_used_words and tok.pos_ == 'PROPN' and extracted_str.replace(\"-\",\"\").title().find(tok.text)!=-1 and len(tok.text)>3):\n",
    "            COMMENT = \"Both companies have same proper name\"\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b27317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_also_person(real_str, extracted_str,nlp):\n",
    "    global COMMENT\n",
    "    doc = nlp(real_str)\n",
    "    for ent in doc.ents: \n",
    "        if(ent.label_ == 'PERSON' and extracted_str.find(ent.text)!=-1 and len(ent.label > 2)):\n",
    "            COMMENT = \"Both companies have same person name\"\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd0ace1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_both_unique(real_words, extracted_words):#check if organisation name contains unique word\n",
    "    global COMMENT\n",
    "\n",
    "    if(len(real_words)==1 and len(extracted_str.replace(\"-\",\"\").split(\" \"))==1):#one subword - not valid\n",
    "        return False\n",
    "    for word in real_words:\n",
    "        if(word in extracted_words and word not in tokenizer.get_vocab() and word.lower() not in commonly_used_words):\n",
    "            COMMENT = \"Both companies have unique word\"\n",
    "            return True\n",
    "    #words = real_str.split(\" \")\n",
    "    #for word in words:\n",
    "    #    if(word in extracted_words and word not in tokenizer.get_vocab() and word.lower() not in commonly_used_words):\n",
    "    #        COMMENT = \"Both companies have unique word\"\n",
    "    #        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "047a270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_extracted_contain_real(words, extracted_words):#check if organisation name contains person name\n",
    "    #if(extracted_str.find(real_str) !=-1):\n",
    "    #    return True\n",
    "    for word in words:\n",
    "        if(word not in extracted_words):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f9cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_name_match(words, extracted_words):#check if organisation name contains person name\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if(word in extracted_words and word not in commonly_used_words):\n",
    "            count += 1\n",
    "    if(count >= 2):\n",
    "        return True\n",
    "        comment = \"More then 1 common word with long name\"\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d667387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_abbreviation(real_str, extracted_str):\n",
    "    global COMMENT\n",
    "    company = real_str.lower()\n",
    "    extracted = extracted_str.replace(\"-\",\" \").lower().split(\" \")\n",
    "    extracted = [elem for elem in extracted if len(elem)!=0]\n",
    "    if not(extracted and company):\n",
    "        return False\n",
    "    if(len(company)!=len(extracted)): \n",
    "        if(company[-1] == 'c' or company[-1] == 'g'):\n",
    "            extracted.append(company[-1])\n",
    "    if(len(company)!=len(extracted)):\n",
    "        return False\n",
    "    \n",
    "    for idx in range(len(extracted)):\n",
    "        if(company[idx]!=extracted[idx][0]):\n",
    "            return False\n",
    "    COMMENT = \"Company is abbreviation\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c27ef955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_complicated_abbreviation(abbrev_str, full_str): #FedEx is Federal Express for example\n",
    "    short_words = re.findall('[A-Z][^A-Z]*', abbrev_str)\n",
    "    full_words = full_str.split()\n",
    "    if(len(short_words)!=len(full_words)  or len(short_words) < 2): \n",
    "        return False\n",
    "    for idx in range(len(short_words)):\n",
    "        if(full_words[idx].find(short_words[idx]) == -1):\n",
    "            return False\n",
    "    COMMENT = \"Company is complicated abbreviation\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f70cf462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_mixed_word(real_words, extracted_words):#check if organisation name contains unique word\n",
    "    global COMMENT\n",
    "    if(len(real_words)==1 and len(extracted_str.replace(\"-\",\"\").split(\" \"))==1):#one subword - not valid\n",
    "        return False\n",
    "    for word in real_words:\n",
    "        if(word in extracted_words  and not word.isupper() and not word.islower() and not word.istitle()):\n",
    "            COMMENT = \"Both companies common mixed word\"\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8673415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_commonly_used_is_common(real_words, extracted_words):\n",
    "    isOkay = False\n",
    "    for word in real_words:\n",
    "        if(word in extracted_words and word not in commonly_used_words):\n",
    "            return False\n",
    "        elif(word in extracted_words and word in commonly_used_words):\n",
    "            isOkay = True\n",
    "    return isOkay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89778e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_valid_match(\"Bank of america\",\"BofA merril linch\"))\n",
    "print(is_complicated_abbreviation(\"Chipotle\",\"Chipotle Mexican Grill\"))\n",
    "print(is_complicated_abbreviation(\"FedEx\",\"Federal Express\"))\n",
    "print(is_valid_match(\"American International\",\"American International Group\"))\n",
    "print(is_extracted_contain_real(\"Alcoa\",\"Gary Hill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbc8e2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "0.7111111111111111\n",
      "0.8888888888888888\n",
      "0.5384615384615384\n",
      "0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "print(\"Nemours\" in tokenizer.get_vocab())\n",
    "print(is_valid_match(\"Yum! Brands\",\"Jerry Dean\"))\n",
    "print(is_also_proper(\"BNY Mellon\",\"Bank of New York Mellon\",nlp))\n",
    "print(is_both_unique(\"Yum Brands\",\"Conagra Brands\"))\n",
    "print(is_both_unique(\"Sl Green Realty\",\"Slg\"))\n",
    "print(is_both_unique(\"Dupont De Nemours\",\"Ei Du Pont De Nemours\"))\n",
    "print(is_valid_match(\"Jp Morgan Chase\",\"Jpmorgan\"))\n",
    "print(is_extracted_contain_real(\"Alcoa\",\"Gary Hill\"))\n",
    "print(is_valid_match(\"Freeport-Mcmoran\",\"Mcmoran\"))\n",
    "print(is_valid_match(\"Jp Morgan Chase\",\"Jpmorgan\"))\n",
    "print(difflib.SequenceMatcher(None,\"Bank of america merril linch\",\"BofA merril linch\").ratio())\n",
    "print(difflib.SequenceMatcher(None,\"Curtiss-Wright\",\"Curtis Wright\").ratio())\n",
    "print(difflib.SequenceMatcher(None,\"Gordon Slater\",\"Goldman Sachs\").ratio())\n",
    "print(difflib.SequenceMatcher(None,\"Mes Inc\",\"My Inc\").ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44a88e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "importing Jupyter notebook from organisations_normalization.ipynb\n",
      "RPM Inc\n",
      "44708\n",
      "44708\n",
      "44708\n",
      "44708\n",
      "55729\n",
      "True\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(common_mixed_word(\"First BanCorp\", \"First BanCorp New\"))\n",
    "words = \"RPM Inc\".lower().replace(\"-\",\" \").split(\" \")#for walmart and other\n",
    "long_words = \"RPM Technology Inc\".lower().replace(\"-\",\" \").split(\" \")#for walmart and other\n",
    "from organisations_normalization import string_normalize        \n",
    "print(long_name_match(words,long_words))\n",
    "print(difflib.SequenceMatcher(None,\"New Yorker\",\"New York Times\").ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e98ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting sector data\n",
    "#matching:\n",
    "df_sectors = pd.read_csv(\"ls new handling normalized tickers holdings with industry.csv\",index_col=False,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0482da2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major Banks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(str(df_sectors.loc[df_sectors['Name'] == 'Bank Of America']['Industry'].iloc[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c34cbfdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44708\n",
      "44708\n",
      "6161\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "42000\n",
      "44000\n",
      "not found 2907\n",
      "found 61812\n",
      "total 64719\n",
      "found_res =  0.9550827423167849\n",
      "perfect_res =  0.8066101144949706\n",
      "contained_res =  0.06997944962066781\n",
      "Real company         61812\n",
      "Extracted company    61812\n",
      "Metrix               61812\n",
      "Comment              61812\n",
      "Article              61812\n",
      "dtype: int64\n",
      "Real company         2724\n",
      "Extracted company    2724\n",
      "Metrix               2724\n",
      "Comment              2724\n",
      "Article              2724\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#matching:\n",
    "import json, itertools\n",
    "from organisations_normalization import string_normalize\n",
    "res_df = pd.DataFrame(columns=['Real company','Extracted company','Metrix','Comment','Article'])\n",
    "df_keywords = pd.read_csv(\"dummy_keywords no copies.csv\")\n",
    "\n",
    "bigram_keywords = df_keywords['Sentence']\n",
    "\n",
    "found_num = 0\n",
    "not_found_num = 0\n",
    "total = 0\n",
    "\n",
    "labeled_companies = df_labels['Name']\n",
    "news = df_news['News']\n",
    "print(len(news))\n",
    "print(len(labeled_companies))\n",
    "headline = df_news['Keywords']\n",
    "keywords = df_news['Headline']\n",
    "#for i in range (50):\n",
    "#    print(keywords[i])\n",
    "#for i in range (50):\n",
    "#    print(headline[i])\n",
    "    #print(keywords[i].replace(\"{\",\"\").replace(\"}\",\"\").replace('\"',\"\").split(\",\"))\n",
    "\n",
    "print(len(df_sectors))\n",
    "COEFFS = {'contain_real': 0.9,'is_valid_match': 0.8,'is_both_unique': 0.8,'is_also_proper': 0.8,'is_abbreviation': 0.5,'is_also_person':0.8}\n",
    "ARTICLES_NUM = len(labeled_companies)\n",
    "extracted_companies = df_all_extracted_companies['Name']\n",
    "perfect_companies = 0\n",
    "contain_real_companies = 0\n",
    "\n",
    "for idx in range (ARTICLES_NUM):\n",
    "    labeled = labeled_companies[idx].split('\\t')\n",
    "    long_labeled = df_labels['Long name'][idx].split('\\t')\n",
    "    extracted = extracted_companies[idx].split('\\t')\n",
    "    keywords = bigram_keywords[idx]\n",
    "    total += len(labeled)\n",
    "    for labeled_elem, long_labeled_elem in zip(labeled, long_labeled):\n",
    "        curr_sector = str(df_sectors.loc[df_sectors['Name'] == labeled_elem]['Industry'].iloc[0])\n",
    "        curr_keywords = json.loads(bigram_keywords[idx].replace(\"'\",'\"')) # get list from ist str representation\n",
    "        max_metrix = 0.0\n",
    "        COMMENT = \"\"\n",
    "        for extracted_elem in extracted:\n",
    "            if(extracted_elem == \"Not Avaliable\" or extracted_elem.lower() == \"nan\"):\n",
    "                continue\n",
    "            labeled_str = labeled_elem.replace(\" \",\"\").replace(\"-\",\"\").lower()\n",
    "            long_str = long_labeled_elem.replace(\" \",\"\").replace(\"-\",\"\").lower()\n",
    "            extracted_str = extracted_elem.replace(\" \",\"\").replace(\"-\",\"\").lower()\n",
    "            metrix = difflib.SequenceMatcher(None,labeled_str,extracted_str).ratio()\n",
    "            long_metrix = difflib.SequenceMatcher(None,labeled_str,extracted_str).ratio()\n",
    "            \n",
    "            \n",
    "            labeled_words = labeled_elem.lower().replace(\"-\",\" \").split(\" \")#for walmart and other\n",
    "            labeled_long_words = long_labeled_elem.lower().replace(\"-\",\" \").split(\" \")#for walmart and other\n",
    "            extracted_words = extracted_elem.lower().replace(\"-\",\" \").split(\" \")\n",
    "\n",
    "            if (long_metrix == 1.0 or metrix == 1.0 or max_metrix == 1.0 or labeled_str.replace(\"group\",\"\") == extracted_str or labeled_str.replace(\"&\",\"and\") == extracted_str or extracted_str.replace(\"&\",\"and\") == labeled_str):\n",
    "                max_elem = extracted_elem\n",
    "                max_metrix = 1.0\n",
    "                COMMENT = \"\"\n",
    "                perfect_companies += 1\n",
    "                break\n",
    "            if (is_extracted_contain_real(labeled_words,extracted_words) or (extracted_str.find(labeled_str.replace(\"group\",\"\")) !=-1 and len(extracted_words) > 1)):\n",
    "                max_elem = extracted_elem\n",
    "                max_metrix = 1.0\n",
    "                contain_real_companies += 1\n",
    "                COMMENT = \"Extracted company contain real\"\n",
    "                break\n",
    "            if(long_name_match(labeled_long_words,extracted_words)):\n",
    "                max_elem = extracted_elem\n",
    "                max_metrix = 1.0\n",
    "                perfect_companies += 1\n",
    "                break\n",
    "            if(only_commonly_used_is_common(labeled_words,extracted_words) and metrix < 0.9):\n",
    "                continue\n",
    "            if (metrix > 0.3 and len(extracted_str) > 2 and (len(labeled_str) > 2) and (is_valid_match(labeled_elem,extracted_elem) or is_valid_match(extracted_elem,labeled_elem) or is_also_proper(labeled_elem,extracted_elem,nlp) or is_both_unique(labeled_words,extracted_words))):\n",
    "                if(0.86 > max_metrix):\n",
    "                    max_metrix = 0.86\n",
    "                    max_elem = extracted_elem\n",
    "            if (is_abbreviation(labeled_elem,extracted_elem) or is_abbreviation(extracted_elem,labeled_elem)):\n",
    "                if(0.81 > max_metrix):\n",
    "                    max_metrix = 0.81\n",
    "                    max_elem = extracted_elem\n",
    "            if (is_complicated_abbreviation(labeled_elem,extracted_elem) or is_complicated_abbreviation(extracted_elem,labeled_elem)):\n",
    "                if(0.83 > max_metrix):\n",
    "                    max_metrix = 0.83\n",
    "                    max_elem = extracted_elem\n",
    "            if common_mixed_word(labeled_words,extracted_words):\n",
    "                if(0.85 > max_metrix):\n",
    "                    max_metrix = 0.85\n",
    "                    max_elem = extracted_elem\n",
    "            if metrix > max_metrix:\n",
    "                max_metrix = metrix\n",
    "                max_elem = extracted_elem\n",
    "                COMMENT = \"\"\n",
    "                isOkay = True\n",
    "                for elem in curr_keywords:\n",
    "                    if(not isOkay):\n",
    "                        break\n",
    "                    elem = string_normalize(elem)\n",
    "                    if(labeled_elem.find(elem)!= -1):\n",
    "                        max_metrix = min(1.0, max_metrix + 0.15)\n",
    "                        COMMENT = \"Common keywords\"\n",
    "                        isOKay = False\n",
    "                for word in labeled_words:\n",
    "                    if word.lower() in commonly_used_words:\n",
    "                        continue\n",
    "                    if word in extracted_words  and curr_sector.find(word)!=-1 and len(word) > 2:\n",
    "                        max_metrix = min(1, max_metrix + 0.10)\n",
    "                        COMMENT = \"Common keywords\"\n",
    "                        print(extracted_elem,\" + \", labeled_elem, \" + \", curr_sector, \" + \",elem)\n",
    "                        break\n",
    "        if (max_metrix > 0.95)or(max_metrix > 0.8  and len(labeled_elem) > 2 and len(max_elem) > 2):      \n",
    "            res_df.loc[found_num]=[labeled_elem,max_elem,max_metrix,COMMENT,news[idx]]\n",
    "            found_num += 1\n",
    "        else:\n",
    "            not_found_num += 1\n",
    "    if(idx % 2000 == 0):\n",
    "        print(idx)\n",
    "            #print(labeled_elem,\"+\", extracted,\" best: \",max_elem,\" :idx = \",idx)\n",
    "print(\"not found\", not_found_num)\n",
    "print(\"found\", found_num)\n",
    "print(\"total\",total)\n",
    "print(\"found_res = \",found_num/total)\n",
    "print(\"perfect_res = \",perfect_companies/total)\n",
    "print(\"contained_res = \",contain_real_companies/total)\n",
    "print(res_df.count())\n",
    "res_df.drop_duplicates(subset=['Real company','Extracted company'],inplace=True)\n",
    "print(res_df.count())\n",
    "res_df.to_csv(\"with keyword results/long_str_new_handling.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63075ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only nasdaq:\n",
    "#93,7% - bert ->94,18%\n",
    "#90.9% - spacy\n",
    "#52.3% - nltk\n",
    "#95% - flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "def3f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add  to normalization:\n",
    "#if(elem.find(\" \")!=-1 and extracted_elem.find(\" \")!=-1):# delete words except first with len < 3 if both companies have more than 1 word\n",
    "#                labeled_elem = re.sub(r' \\w{1,2}\\b', '', labeled_elem).strip()\n",
    "#                extracted_elem = re.sub(r' \\w{1,2}\\b', '', extracted_elem).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff35480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#94.7% (73,6% perfect)- spacy\n",
    "#95,7% (73,4% perfect) - bert\n",
    "\n",
    "#no the\n",
    "#found_res =  0.9525623053925643\n",
    "#perfect_res =  0.7489052362580789\n",
    "#contained_res =  0.1019215739787374\n",
    "\n",
    "\n",
    "#strict\n",
    "#found_res =  0.945615362667626\n",
    "#perfect_res =  0.7489052362580789\n",
    "#contained_res =  0.1019215739787374\n",
    "\n",
    "#extended\n",
    "#found_res =  0.9345622805820546\n",
    "#perfect_res =  0.7300492488618179\n",
    "#contained_res =  0.10829787497984146\n",
    "\n",
    "#extended large\n",
    "#found_res =  0.956159829303693\n",
    "#perfect_res =  0.7513862872312712\n",
    "#contained_res =  0.10868243788068625\n",
    "\n",
    "#found_res =  0.9563583133815484\n",
    "#perfect_res =  0.7513862872312712\n",
    "#contained_res =  0.10868243788068625\n",
    "\n",
    "#large + alice strict\n",
    "#found_res =  0.964357383223735\n",
    "#perfect_res =  0.8078941681331234\n",
    "#contained_res =  0.05939921583155815\n",
    "\n",
    "#news handled (not remove &)\n",
    "#found_res =  0.9623603578547258\n",
    "#perfect_res =  0.8097003971013149\n",
    "#contained_res =  0.0542035569152799\n",
    "\n",
    "#used keywords\n",
    "#found_res =  0.9624994205720113\n",
    "#perfect_res =  0.8117245322084705\n",
    "#contained_res =  0.05409539702405785\n",
    "\n",
    "#new normalization :\n",
    "#found_res =  0.9640445618751835\n",
    "#perfect_res =  0.824471947959641\n",
    "#contained_res =  0.05247299865572706\n",
    "\n",
    "#found_res =  0.9595636520959842\n",
    "#perfect_res =  0.8135323475331819\n",
    "#contained_res =  0.07673171711553022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
